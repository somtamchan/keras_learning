{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import os\n",
    "\n",
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 1\n",
    "data_augmentation = True\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar10_trained_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "Using real-time data augmentation.\n",
      "Epoch 1/1\n",
      "1562/1562 [==============================] - 259s 166ms/step - loss: 1.8942 - acc: 0.3075 - val_loss: 1.6415 - val_acc: 0.4014\n",
      "Saved trained model at /Users/yoshimi/dev/saved_models/keras_cifar10_trained_model.h5 \n"
     ]
    }
   ],
   "source": [
    "## kerasで学習する\n",
    "\n",
    "'''\n",
    "#Train a simple deep CNN on the CIFAR10 small images dataset.\n",
    "It gets to 75% validation accuracy in 25 epochs, and 79% after 50 epochs.\n",
    "(it's still underfitting at that point, though).\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "# The data, split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        # randomly shift images horizontally (fraction of total width)\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically (fraction of total height)\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.,  # set range for random shear\n",
    "        zoom_range=0.,  # set range for random zoom\n",
    "        channel_shift_range=0.,  # set range for random channel shifts\n",
    "        # set mode for filling points outside the input boundaries\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,  # value used for fill_mode = \"constant\"\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False,  # randomly flip images\n",
    "        # set rescaling factor (applied before any other transformation)\n",
    "        rescale=None,\n",
    "        # set function that will be applied on each input\n",
    "        preprocessing_function=None,\n",
    "        # image data format, either \"channels_first\" or \"channels_last\"\n",
    "        data_format=None,\n",
    "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "        validation_split=0.0)\n",
    "\n",
    "    # Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                     batch_size=batch_size),\n",
    "                        epochs=epochs,\n",
    "                        steps_per_epoch=int(len(x_train) / batch_size),\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        workers=4)\n",
    "\n",
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)\n",
    "\n",
    "# Score trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding:utf-8\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from keras.models import load_model\n",
    "\n",
    "K.set_learning_phase(1) #set learning phase\n",
    "\n",
    "\n",
    "\n",
    "def Grad_Cam(input_model, x, layer_name):\n",
    "    '''\n",
    "    Args:\n",
    "       input_model: モデルオブジェクト\n",
    "       x: 画像(array)\n",
    "       layer_name: 畳み込み層の名前\n",
    "\n",
    "    Returns:\n",
    "       jetcam: 影響の大きい箇所を色付けした画像(array)\n",
    "\n",
    "    '''\n",
    "\n",
    "    # 前処理\n",
    "    X = np.expand_dims(x, axis=0)\n",
    "\n",
    "    X = X.astype('float32')\n",
    "    preprocessed_input = X / 255.0\n",
    "\n",
    "\n",
    "    # 予測クラスの算出\n",
    "\n",
    "    predictions = model.predict(preprocessed_input)\n",
    "    class_idx = np.argmax(predictions[0])\n",
    "    print(class_idx)\n",
    "    class_output = model.output[:, class_idx]\n",
    "\n",
    "\n",
    "    #  勾配を取得\n",
    "\n",
    "    conv_output = model.get_layer(layer_name).output   # layer_nameのレイヤーのアウトプット\n",
    "    grads = K.gradients(class_output, conv_output)[0]  # gradients(loss, variables) で、variablesのlossに関しての勾配を返す\n",
    "    gradient_function = K.function([model.input], [conv_output, grads])  # model.inputを入力すると、conv_outputとgradsを出力する関数\n",
    "\n",
    "    output, grads_val = gradient_function([preprocessed_input])\n",
    "    output, grads_val = output[0], grads_val[0]\n",
    "\n",
    "    # 重みを平均化して、レイヤーのアウトプットに乗じる\n",
    "    weights = np.mean(grads_val, axis=(0, 1))\n",
    "    cam = np.dot(output, weights)\n",
    "\n",
    "\n",
    "    # 画像化してヒートマップにして合成\n",
    "\n",
    "    cam = cv2.resize(cam, (32, 32), cv2.INTER_LINEAR) # 画像サイズは200で処理したので\n",
    "    cam = np.maximum(cam, 0) \n",
    "    cam = cam / cam.max()\n",
    "\n",
    "    jetcam = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)  # モノクロ画像に疑似的に色をつける\n",
    "    jetcam = cv2.cvtColor(jetcam, cv2.COLOR_BGR2RGB)  # 色をRGBに変換\n",
    "    jetcam = (np.float32(jetcam) + x / 2)   # もとの画像に合成\n",
    "\n",
    "    return jetcam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAJ2ElEQVR4nC3VWY9c6UHG8Xd/z37q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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32 at 0x12D5BFBA8>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## データの読み込み\n",
    "model = load_model(model_path)\n",
    "x = img_to_array(load_img('./cat.jpg', target_size=(32,32)))\n",
    "array_to_img(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAJkklEQVR4nAXBWZNd11UA4LXWns65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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32 at 0x12BAB14A8>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Grad_Camを試す\n",
    "image = Grad_Cam(model, x, 'activation_16') \n",
    "array_to_img(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
